{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62859d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Lesson 1-Stripped [Code only].ipynb'  'Lesson 5-Stripped [Code Only].ipynb'\r\n",
      "'Lesson 2-Stripped[Code only].ipynb'    aclImdb\r\n",
      "'Lesson 3-Stripped [Code only].ipynb'   aclImdb_v1.tar\r\n",
      "'Lesson 4-Stripped [Code only].ipynb'   tmp\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b5b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c382ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fastai.nlp import *\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1e15f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./aclImdb/\"\n",
    "names = ['neg','pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e58dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_labels_from_folders(path, folders):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(folders):\n",
    "        for fname in glob(os.path.join(path, label, '*.*')):\n",
    "            texts.append(open(fname, 'r').read())\n",
    "            labels.append(idx)\n",
    "    return texts, np.array(labels).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "673c64e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn,trn_y = texts_labels_from_folders(f'{PATH}train',names)\n",
    "val,val_y = texts_labels_from_folders(f'{PATH}test',names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9fa0433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"College students, who are clearing out a condemned dormitory, are stalked by an elusive killer.<br /><br />The Dorm That Dripped Blood (aka Pranks) is a bit of a mixed bag for slasher fans. The movies production values are pretty low and the story for the most part is pretty routine, there's even a creepy bum hanging around for a red herring. In fact much of the story's build-up is pretty forgettable, save for one or two brutal murders. But the movie is really made better by its surprisingly intense climax (in an atmospheric setting) and one fairly bold, unconventional conclusion.<br /><br />The cast is lackluster for the most part. Stephen Sachs is the best of the lot as he does a pretty nice turn in character. Also look for a young Daphne Zuniga as an ill-fated student.<br /><br />Over all this is a pretty standard B slasher effort, but the finale is well worth savoring and for this viewer saved the movie from being a complete ho-hum.<br /><br />** out of ****\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3893a969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "077ca8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_tok = re.compile('([!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~“”¨«»®´·º½¾¿¡§£₤‘’])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e66f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a8f7cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "veczr = CountVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f1a0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_term_doc = veczr.fit_transform(trn)\n",
    "val_term_doc = veczr.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1ef5a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x75132 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3749745 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b998e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x75132 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 123 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8945fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aussie', 'aussies', 'austen', 'austeniana', 'austens']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = veczr.get_feature_names(); vocab[5000:5005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d5cb649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(aka',\n",
       " '(in',\n",
       " '****',\n",
       " '/>**',\n",
       " '/><br',\n",
       " '/>over',\n",
       " '/>the',\n",
       " 'a',\n",
       " 'all',\n",
       " 'also',\n",
       " 'an',\n",
       " 'and',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'atmospheric',\n",
       " 'b',\n",
       " 'bag',\n",
       " 'being',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bit',\n",
       " 'blood',\n",
       " 'bold,',\n",
       " 'brutal',\n",
       " 'build-up',\n",
       " 'bum',\n",
       " 'but',\n",
       " 'by',\n",
       " 'cast',\n",
       " 'character.',\n",
       " 'clearing',\n",
       " 'climax',\n",
       " 'college',\n",
       " 'complete',\n",
       " 'conclusion.<br',\n",
       " 'condemned',\n",
       " 'creepy',\n",
       " 'daphne',\n",
       " 'does',\n",
       " 'dorm',\n",
       " 'dormitory,',\n",
       " 'dripped',\n",
       " 'effort,',\n",
       " 'elusive',\n",
       " 'even',\n",
       " 'fact',\n",
       " 'fairly',\n",
       " 'fans.',\n",
       " 'finale',\n",
       " 'for',\n",
       " 'forgettable,',\n",
       " 'from',\n",
       " 'hanging',\n",
       " 'he',\n",
       " 'herring.',\n",
       " 'ho-hum.<br',\n",
       " 'ill-fated',\n",
       " 'in',\n",
       " 'intense',\n",
       " 'is',\n",
       " 'its',\n",
       " 'killer.<br',\n",
       " 'lackluster',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'low',\n",
       " 'made',\n",
       " 'mixed',\n",
       " 'most',\n",
       " 'movie',\n",
       " 'movies',\n",
       " 'much',\n",
       " 'murders.',\n",
       " 'nice',\n",
       " 'of',\n",
       " 'one',\n",
       " 'or',\n",
       " 'out',\n",
       " 'part',\n",
       " 'part.',\n",
       " 'pranks)',\n",
       " 'pretty',\n",
       " 'production',\n",
       " 'really',\n",
       " 'red',\n",
       " 'routine,',\n",
       " 'sachs',\n",
       " 'save',\n",
       " 'saved',\n",
       " 'savoring',\n",
       " 'setting)',\n",
       " 'slasher',\n",
       " 'stalked',\n",
       " 'standard',\n",
       " 'stephen',\n",
       " 'story',\n",
       " \"story's\",\n",
       " 'student.<br',\n",
       " 'students,',\n",
       " 'surprisingly',\n",
       " 'that',\n",
       " 'the',\n",
       " \"there's\",\n",
       " 'this',\n",
       " 'turn',\n",
       " 'two',\n",
       " 'unconventional',\n",
       " 'values',\n",
       " 'viewer',\n",
       " 'well',\n",
       " 'who',\n",
       " 'worth',\n",
       " 'young',\n",
       " 'zuniga'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0 = set([o.lower() for o in trn[0].split(' ')]); w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a77fbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0865acfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1297"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veczr.vocabulary_['absurd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d874b24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc[0,1297]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f5ea30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc[0,5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5f23f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr(y_i):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a04c852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=trn_term_doc\n",
    "y=trn_y\n",
    "\n",
    "r = np.log(pr(1)/pr(0))\n",
    "b = np.log((y==1).mean() / (y==0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba48c809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81656"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_term_doc @ r.T + b\n",
    "preds = pre_preds.T>0\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a08488c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83016"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=trn_term_doc.sign()\n",
    "r = np.log(pr(1)/pr(0))\n",
    "\n",
    "pre_preds = val_term_doc.sign() @ r.T + b\n",
    "preds = pre_preds.T>0\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "208d831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Original nb had dual =True, check why\n",
    "# Note 2: 0.19.2 was the sklearn version there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "847da581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83392"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=1e8, )#dual=True)\n",
    "m.fit(x, y)\n",
    "preds = m.predict(val_term_doc)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23d22d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85708"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=1e8)\n",
    "m.fit(trn_term_doc.sign(), y)\n",
    "preds = m.predict(val_term_doc.sign())\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8d12e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: In original notebook, this is higher, `0.84x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "38197965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/protonsuper/anaconda3/envs/fastai-ml/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7592"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1)\n",
    "m.fit(x, y)\n",
    "preds = m.predict(val_term_doc)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "13dad9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/protonsuper/anaconda3/envs/fastai-ml/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88432"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1)\n",
    "m.fit(trn_term_doc.sign(), y)\n",
    "preds = m.predict(val_term_doc.sign())\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "98aaa93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "veczr =  CountVectorizer(ngram_range=(1,3), tokenizer=tokenize, max_features=800000)\n",
    "trn_term_doc = veczr.fit_transform(trn)\n",
    "val_term_doc = veczr.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2963dd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 800000)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "27d5ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = veczr.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2018f753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['by vast', 'by vengeance', 'by vengeance .', 'by vera', 'by vera miles']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[200000:200005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb4616de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=trn_y\n",
    "x=trn_term_doc.sign()\n",
    "val_x = val_term_doc.sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9365590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.log(pr(1) / pr(0))\n",
    "b = np.log((y==1).mean() / (y==0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "daa52d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/protonsuper/anaconda3/envs/fastai-ml/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90472"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1)\n",
    "m.fit(x, y);\n",
    "\n",
    "preds = m.predict(val_x)\n",
    "(preds.T==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0768174e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 800000),\n",
       " matrix([[-0.05468386, -0.16100472, -0.24783616, ...,  1.09861229,\n",
       "          -0.69314718, -0.69314718]]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c19951b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.94678442, 0.85128806, 0.7804878 , ..., 3.        , 0.5       ,\n",
       "         0.5       ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "97d487dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91748"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_nb = x.multiply(r)\n",
    "m = LogisticRegression(C=0.1)\n",
    "m.fit(x_nb, y);\n",
    "\n",
    "val_x_nb = val_x.multiply(r)\n",
    "preds = m.predict(val_x_nb)\n",
    "(preds.T==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63fa106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl=2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1230fc",
   "metadata": {},
   "source": [
    "# Note: Need to make things work after this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48208496",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextClassifierData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2250/827473866.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Here is how we get a model from a bag of words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextClassifierData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_term_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_term_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TextClassifierData' is not defined"
     ]
    }
   ],
   "source": [
    "# Here is how we get a model from a bag of words\n",
    "md = TextClassifierData.from_bow(trn_term_doc, trn_y, val_term_doc, val_y, sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0dab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = md.dotprod_nb_learner()\n",
    "learner.fit(0.02, 1, wds=1e-6, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(0.02, 2, wds=1e-6, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39221f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(0.02, 2, wds=1e-6, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dea8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
